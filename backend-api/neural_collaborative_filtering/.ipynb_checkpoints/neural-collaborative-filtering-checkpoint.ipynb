{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Collaborative Filtering (NCF)\n",
    "Neural Matrix Factorization (NeuMF) combines Generalized Matrix Factorization (GMF) with deep neural networks to model user-item interactions. The model is trained on implicit feedback data and predicts the likelihood of a user interacting with an item.\n",
    "\n",
    "Based on https://github.com/recommenders-team/recommenders/blob/main/examples/02_model_collaborative_filtering/ncf_deep_dive.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# General imports\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR') # only show error messages\n",
    "\n",
    "from utils.timer import Timer\n",
    "# from model.ncf_singlenode import NCF\n",
    "# from model.dataset import Dataset as NCFDataset\n",
    "# from neural_collaborative_filtering.dataset.splitters import python_chrono_split\n",
    "# from neural_collaborative_filtering.evaluation.evaluation import (\n",
    "#     map, ndcg_at_k, precision_at_k, recall_at_k\n",
    "# )\n",
    "# from utils.constants import SEED as DEFAULT_SEED\n",
    "# from utils.notebook_utils import store_metadata\n",
    "\n",
    "# print(\"System version: {}\".format(sys.version))\n",
    "# print(\"Pandas version: {}\".format(pd.__version__))\n",
    "# print(\"Tensorflow version: {}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m items_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/items.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m ratings_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/ratings.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(ratings_df, items_df, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmovie_id\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "items_df = pd.read_csv('../data/items.csv')\n",
    "ratings_df = pd.read_csv('../data/ratings.csv')\n",
    "df = pd.merge(ratings_df, items_df, on='movie_id')\n",
    "# keep only required columns\n",
    "df = df[['user_id', 'movie_id', 'rating', 'unix_timestamp', 'title']]\n",
    "print(\"number of unique users: \", df['user_id'].nunique())\n",
    "print(\"number of unique movies: \", df['movie_id'].nunique())\n",
    "print(\"number of ratings: \", len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In some cases a user might have rated the same movie multiple times. We will keep the latest rating and remove the rest.\n",
    "df = df.sort_values(by='unix_timestamp', ascending=False).drop_duplicates(subset=['user_id', 'movie_id'], keep='first')\n",
    "print(\"number of ratings after removing duplicates: \", len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of all users\n",
    "unique_users = df['user_id'].unique() \n",
    "# creating a list of all movie names in it\n",
    "unique_movies = df['movie_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 256\n",
    "SEED = 42 # Set None for non-deterministic results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split into train and test sets\n",
    "# train, test = train_test_split(df, test_size=0.20)\n",
    "# print(\"train shape: \", train.shape)\n",
    "# print(\"test shape: \", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test = python_chrono_split(df, 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out any users or items in the test set that do not appear in the training set\n",
    "train_users = train['user_id'].unique()\n",
    "train_movies = train['movie_id'].unique()\n",
    "test = test[(test['user_id'].isin(train_users)) & (test['movie_id'].isin(train_movies))]\n",
    "print(\"train shape: \", train.shape)\n",
    "print(\"test shape: \", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test set containing the last interaction for each user as for the leave-one-out evaluation.\n",
    "leave_one_out_test = test.groupby('user_id').last().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write datasets to csv files\n",
    "train_file = \"./train.csv\"\n",
    "test_file = \"./test.csv\"\n",
    "leave_one_out_test_file = \"./leave_one_out_test.csv\"\n",
    "train.to_csv(train_file, index=False)\n",
    "test.to_csv(test_file, index=False)\n",
    "leave_one_out_test.to_csv(leave_one_out_test_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = NCFDataset(train_file=train_file, test_file=leave_one_out_test_file, seed=SEED, overwrite_test_file_full=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "movielens-3-10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
